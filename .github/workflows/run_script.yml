name: Run Web Scraping Script Every Hour

on:
  schedule:
    # 이 크론 표현식은 워크플로우가 매 시간마다 실행되도록 설정합니다.
    - cron: "0 * * * *"
  workflow_dispatch: # 수동 실행을 위한 설정

jobs:
  scrape_jobs:
    runs-on: ubuntu-latest

    steps:
      # Step 1: 레포지토리 코드 체크아웃
      - name: Checkout repository
        uses: actions/checkout@v2

      # Step 2: Python 3.9 설정
      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      # Step 3: 필요한 패키지 설치
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium

      # Step 4: Chrome WebDriver 다운로드 (Chrome 133에 맞는 버전)
      - name: Download Chrome WebDriver
        run: |
          wget https://chromedriver.storage.googleapis.com/133.0.6943.126/chromedriver_linux64.zip
          unzip chromedriver_linux64.zip
          sudo mv chromedriver /usr/local/bin/chromedriver
          sudo chmod +x /usr/local/bin/chromedriver

      # Step 5: 스크립트 실행
      - name: Run web scraping script
        run: |
          python script.py
